\begin{abstract}
    Ensuring safety and achieving human-level driving performance remain significant challenges for autonomous vehicles. While model-based reinforcement learning with planners enhances sample efficiency and facilitates policy exploration, many such methods rely on planners employing fixed parameters to balance expected rewards and risks, which limits their adaptability in dynamic traffic scenarios. Furthermore, studies use simplified traffic simulations for training and evaluation often results in algorithms that overfit to homogeneous traffic agents, resulting in overly optimistic performance.
    To address these limitations, we introduce RiskDreamer, a novel framework that employs batch planning within the latent space of the world model. facilitating efficiently exploration. Notably, we extend the action space to incorporate balancing factors as direct action outputs, optimized at each step. This enables the dynamic weighting of entropy, risk, and expected reward, achieving adaptable behavior planning in diverse traffic conditions.
    Furthermore, RiskDreamer is trained within a trustworthy traffic scenario generation framework based on optimization algorithms, capable of producing heterogeneous traffic agents from real trajectory datasets. The microscopic behavioral characteristics and macroscopic aggregate metrics of the generated background agents align with real-world statistical distributions. Through experimental results, we demonstrate that our method achieve competitive performance compared to strong baseline methods. The code for our research is available at \href{https://github.com/Gaochengzhi/RiskDreamer}{https://github.com/Gaochengzhi/RiskDreamer}.
\end{abstract}
\begin{IEEEkeywords}
Reinforcement learning, World model, Autonomous vehicle, Traffic simulation.
\end{IEEEkeywords}