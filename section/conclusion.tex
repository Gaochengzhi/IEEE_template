\section{Conclusion}
\label{sec:conclusion}
In this paper, we introduced RiskDreamer, a novel model-based reinforcement learning framework that leverages batch planning in a latent space to dynamically balance risk, entropy, and expected reward. By extending the action space to output these balancing factors directly, our approach addresses the limitations of fixed-parameter risk allocation and overcomes the shortcomings of overly simplified or homogeneous traffic simulations. The trustworthy traffic scenario generation framework further reinforces the realism of the simulation environment by calibrating diverse traffic agents' behaviors to match real-world statistics.
\subsection{Evaluation Results}
The experimental evaluations across three typical autonomous driving scenarios demonstrate the effectiveness of the proposed RiskDreamer framework. In the MERGE scenario, RiskDreamer achieves a competitive composite score by balancing speed, navigation success, and risk, showcasing its ability to navigate complex merging situations without being overly conservative or reckless. The NARROW scenario further highlights RiskDreamer's capability in challenging environments, where it achieves the highest navigation score and a strong overall composite score, indicating effective maneuvering in constrained spaces. While in the STOP scenario, safety-focused algorithms achieved higher composite scores due to their emphasis on minimizing risk, RiskDreamer still demonstrated its improvements against baseline DreamerV3. Compared to baseline methods, RiskDreamer exhibits a more adaptive behavior, avoiding the high-risk tendencies of purely performance-driven approaches like PETS and the overly cautious nature of some SafeRL methods such as CPO and PPOLag in dynamic scenarios. The quantitative analysis further supports these observations, confirming RiskDreamer's ability to dynamically adjust its behavior based on the specific scenario demands.

\subsection{Limitations and Future Work}
Despite RiskDreamer's promising performance, there are several limitations and future research directions need to be taken into consideration. Firstly, due to computational constraints, our current implementation chooses a state-based environment representation.  Future work could explore richer, more realistic perception by incorporating vision-based or multi-modal sensory inputs, enhancing the agent's understanding of complex traffic scenarios. Secondly, while our trustworthy traffic scenario generator improves realism, SUMO remains a simplified traffic simulation environment with a relatively limited dataset.  Future research could integrate larger-scale, real-world trajectory datasets and explore more advanced simulators such as CARLA to further enhance the fidelity of the training and evaluation environment.  Finally, to more comprehensively validate RiskDreamer's real-world applicability and human-vehicle interaction, future studies should incorporate human-in-the-loop evaluations using driving simulators, bridging the gap between simulation and real-world driving scenarios.